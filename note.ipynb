{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e441894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.1. Lingkungan Teknis & Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b37c12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18665</th>\n",
       "      <td>malah di ingatin wkwk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18666</th>\n",
       "      <td>Iyaa..klo Abah Anies pastiI pinter jawab, tp​ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667</th>\n",
       "      <td>Lebih tertarik baca komentarnya netizen ya 😅 a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18668</th>\n",
       "      <td>12:15 bening mengkilat 😇</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18669</th>\n",
       "      <td>yaelah tong tong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  label\n",
       "18665                              malah di ingatin wkwk      0\n",
       "18666  Iyaa..klo Abah Anies pastiI pinter jawab, tp​ ...      0\n",
       "18667  Lebih tertarik baca komentarnya netizen ya 😅 a...      0\n",
       "18668                           12:15 bening mengkilat 😇      0\n",
       "18669                                   yaelah tong tong      0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset_judol.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a695aa05",
   "metadata": {},
   "source": [
    "### <b> Imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e317c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11288\n",
      "7382\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"label\"] == 0]['label'].count())\n",
    "print(df[df[\"label\"] == 1]['label'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "297d801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data setelah Random Undersampling:\n",
      "label\n",
      "0    7382\n",
      "1    7382\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Asumsikan 'df' adalah DataFrame Anda yang sudah bersih\n",
    "# df['label'] berisi label 0 dan 1\n",
    "\n",
    "# 1. Pisahkan DataFrame berdasarkan kelas\n",
    "df_mayoritas = df[df.label == 0]\n",
    "df_minoritas = df[df.label == 1]\n",
    "\n",
    "# 2. Ambil sampel dari kelas mayoritas sebanyak jumlah kelas minoritas\n",
    "df_mayoritas_undersampled = df_mayoritas.sample(n=len(df_minoritas), random_state=42)\n",
    "\n",
    "# 3. Gabungkan kembali kedua DataFrame\n",
    "df_undersampled = pd.concat([df_mayoritas_undersampled, df_minoritas])\n",
    "\n",
    "# 4. Acak urutan DataFrame agar tidak berurutan (semua 0 dulu baru semua 1)\n",
    "df = df_undersampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verifikasi hasil\n",
    "print(\"Jumlah data setelah Random Undersampling:\")\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0248d78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7382\n",
      "7382\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"label\"] == 0]['label'].count())\n",
    "print(df[df[\"label\"] == 1]['label'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ece809",
   "metadata": {},
   "source": [
    "### <b> Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51431896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casefolding\n",
    "NAMA_KOLOM_TEKS = 'comment'\n",
    "df['comment'] = df[NAMA_KOLOM_TEKS].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1aa711c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Noise Removal:\n",
      "                                             comment  \\\n",
      "0  iya benar, jangan2 jawabannya lebih hebat\\nnge...   \n",
      "1                     gak mikir kali join alexis17 .   \n",
      "2                     wakkaka si perusak mobil kan?😂   \n",
      "3                               tumben g gontok\".an😂   \n",
      "4                            𝘼𝙇𝙀𝙓𝙄𝙎17 emang beda . !   \n",
      "\n",
      "                                          text_clean  \n",
      "0  iya benar jangan2 jawabannya lebih hebat\\nngel...  \n",
      "1                      gak mikir kali join alexis17   \n",
      "2                       wakkaka si perusak mobil kan  \n",
      "3                                  tumben g gontokan  \n",
      "4                                    17 emang beda    \n"
     ]
    }
   ],
   "source": [
    "# Noise Removal\n",
    "df['text_clean'] = df['comment'].str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "\n",
    "print(\"Hasil Noise Removal:\")\n",
    "print(df[['comment', 'text_clean']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89b456f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contoh Normalisasi pada Kalimat Spesifik:\n",
      "Sebelum : 'klo gw depo lg skrg, dpt bonus ga ya?'\n",
      "Sesudah : 'kalau saya deposit lagi sekarang dapat bonus tidak ya'\n"
     ]
    }
   ],
   "source": [
    "# Normalization word\n",
    "kamus_normalisasi = {\n",
    "    'ga': 'tidak', 'gak': 'tidak', 'tdk': 'tidak', 'engga': 'tidak',\n",
    "    'jg': 'juga', 'jgn': 'jangan',\n",
    "    'yg': 'yang', 'utk': 'untuk',\n",
    "    'sm': 'sama', 'dgn': 'dengan',\n",
    "    'klo': 'kalau', 'kalo': 'kalau',\n",
    "    'krn': 'karena',\n",
    "    'bgt': 'banget', 'skrg': 'sekarang',\n",
    "    'trus': 'terus', 'sdh': 'sudah',\n",
    "    'blm': 'belum', 'lg': 'lagi',\n",
    "    'sya': 'saya', 'gw': 'saya', 'gue': 'saya',\n",
    "    'lu': 'kamu', 'loe': 'kamu',\n",
    "    'wkwk': 'tertawa', 'wkwkwk': 'tertawa', 'xixi': 'tertawa',\n",
    "    'depo': 'deposit', 'wd': 'withdraw', 'jp': 'jackpot',\n",
    "    'dpt': 'dapat', 'dapet': 'dapat',\n",
    "}\n",
    "\n",
    "# fungsi normalisasi\n",
    "def normalize_text(text):\n",
    "    # Memecah teks menjadi daftar kata dan mapping ke normalnya (jika ada)\n",
    "    words = text.split()\n",
    "    normalized_words = [kamus_normalisasi.get(word, word) for word in words]\n",
    "\n",
    "    # Menggabungkan kembali kata-kata menjadi satu kalimat\n",
    "    return ' '.join(normalized_words)\n",
    "\n",
    "df['text_clean'] = df['text_clean'].apply(normalize_text)\n",
    "\n",
    "\n",
    "print(\"\\nContoh Normalisasi pada Kalimat Spesifik:\")\n",
    "kalimat_kotor = \"klo gw depo lg skrg, dpt bonus ga ya?\"\n",
    "kalimat_bersih = \"klo gw depo lg skrg dpt bonus ga ya\" # setelah case folding & noise removal\n",
    "kalimat_normal = normalize_text(kalimat_bersih)\n",
    "\n",
    "print(f\"Sebelum : '{kalimat_kotor}'\")\n",
    "print(f\"Sesudah : '{kalimat_normal}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a44ab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Stopword Removal:\n",
      "                                             comment  \\\n",
      "0  iya benar, jangan2 jawabannya lebih hebat\\nnge...   \n",
      "1                     gak mikir kali join alexis17 .   \n",
      "2                     wakkaka si perusak mobil kan?😂   \n",
      "3                               tumben g gontok\".an😂   \n",
      "4                            𝘼𝙇𝙀𝙓𝙄𝙎17 emang beda . !   \n",
      "\n",
      "                                          text_clean  \n",
      "0  iya benar jangan2 jawabannya lebih hebat ngela...  \n",
      "1                     tidak mikir kali join alexis17  \n",
      "2                       wakkaka si perusak mobil kan  \n",
      "3                                  tumben g gontokan  \n",
      "4                                      17 emang beda  \n",
      "\n",
      "Contoh Stopword Removal pada Kalimat Spesifik:\n",
      "Sebelum: 'indonesia butuh orang orang seperti kamu bang saya hormat'\n",
      "Sesudah: 'indonesia butuh orang orang bang hormat'\n"
     ]
    }
   ],
   "source": [
    "# Remove stopword\n",
    "stopword_list = [\n",
    "    'di', 'dan', 'yang', 'untuk', 'pada', 'ke', 'karena', 'ini', 'itu',\n",
    "    'dengan', 'tapi', 'juga', 'adalah', 'saya', 'kamu', 'dia', 'kita', 'kalian',\n",
    "    'mereka', 'saja', 'jika', 'atau', 'dari', 'akan', 'sudah', 'telah',\n",
    "    'belum', 'lagi', 'saat', 'seperti', 'hanya', 'bisa', 'jadi', 'buat',\n",
    "]\n",
    "stopword_set = set(stopword_list)\n",
    "\n",
    "# fungsi untuk menghapus stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopword_set]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Terapkan fungsi stopword removal ke kolom 'text_clean'\n",
    "df['text_clean'] = df['text_clean'].apply(remove_stopwords)\n",
    "\n",
    "print(\"Hasil Stopword Removal:\")\n",
    "print(df[['comment', 'text_clean']].head())\n",
    "\n",
    "# Contoh spesifik untuk menunjukkan perubahan\n",
    "print(\"\\nContoh Stopword Removal pada Kalimat Spesifik:\")\n",
    "kalimat_sebelum = \"indonesia butuh orang orang seperti kamu bang saya hormat\" # setelah normalisasi\n",
    "kalimat_sesudah = remove_stopwords(kalimat_sebelum)\n",
    "\n",
    "print(f\"Sebelum: '{kalimat_sebelum}'\")\n",
    "print(f\"Sesudah: '{kalimat_sesudah}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fd01e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gak mikir kali join alexis17 .</td>\n",
       "      <td>1</td>\n",
       "      <td>tidak mikir kali join alexis17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>𝘼𝙇𝙀𝙓𝙄𝙎17 emang beda . !</td>\n",
       "      <td>1</td>\n",
       "      <td>17 emang beda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gk ada bosan nya aku sama ⭐𝘼𝙇𝙀𝙓𝙄𝙎17</td>\n",
       "      <td>1</td>\n",
       "      <td>gk ada bosan nya aku sama 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dari awal cobain sampe sekarang, gak pernah ny...</td>\n",
       "      <td>1</td>\n",
       "      <td>awal cobain sampe sekarang tidak pernah nyesel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>grafis 𝘿 𝐄 𝑊 а 𝘿 о 𝙍 а keren banget , bikin be...</td>\n",
       "      <td>1</td>\n",
       "      <td>grafis keren banget bikin betah main</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment  label  \\\n",
       "1                      gak mikir kali join alexis17 .      1   \n",
       "4                             𝘼𝙇𝙀𝙓𝙄𝙎17 emang beda . !      1   \n",
       "7                 gk ada bosan nya aku sama ⭐𝘼𝙇𝙀𝙓𝙄𝙎17      1   \n",
       "15  dari awal cobain sampe sekarang, gak pernah ny...      1   \n",
       "17  grafis 𝘿 𝐄 𝑊 а 𝘿 о 𝙍 а keren banget , bikin be...      1   \n",
       "\n",
       "                                           text_clean  \n",
       "1                      tidak mikir kali join alexis17  \n",
       "4                                       17 emang beda  \n",
       "7                        gk ada bosan nya aku sama 17  \n",
       "15  awal cobain sampe sekarang tidak pernah nyesel...  \n",
       "17               grafis keren banget bikin betah main  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a88b8",
   "metadata": {},
   "source": [
    "### <b> Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "598343d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X dan y untuk memastikan alur yang jelas\n",
    "X = df['text_clean'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Membagi data menjadi data latih dan uji.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "VOCAB_SIZE = 10000  # Jumlah kata unik yang akan kita simpan dalam kamus\n",
    "MAX_SEQUENCE_LENGTH = 128 # Panjang maksimal setiap sekuens komentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7489016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oov_token: Kata yang tidak ada di kamus akan diubah menjadi token '<unk>'.\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "#  Mengubah Teks menjadi Sekuens Angka\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e5de438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyeragamkan Panjang Sekuens\n",
    "X_train_padded = pad_sequences(\n",
    "    X_train_sequences,\n",
    "    maxlen=MAX_SEQUENCE_LENGTH,\n",
    "    padding='post',\n",
    "    truncating='post'\n",
    ")\n",
    "\n",
    "X_test_padded = pad_sequences(\n",
    "    X_test_sequences,\n",
    "    maxlen=MAX_SEQUENCE_LENGTH,\n",
    "    padding='post',\n",
    "    truncating='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75a24cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses Vectorization Selesai.\n",
      "--------------------------------------------------\n",
      "Teks Asli (setelah cleaning): \n",
      "malem nungguin update alexis17\n",
      "\n",
      "Setelah diubah menjadi sekuens angka: \n",
      "[405, 575, 466, 3]\n",
      "\n",
      "Setelah di-padding menjadi 128 elemen: \n",
      "[405 575 466   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "--------------------------------------------------\n",
      "Bentuk (shape) dari data latih akhir: (11811, 128)\n",
      "Bentuk (shape) dari data uji akhir: (2953, 128)\n"
     ]
    }
   ],
   "source": [
    "# --- Verifikasi Hasil ---\n",
    "print(\"Proses Vectorization Selesai.\")\n",
    "print(\"-\" * 50)\n",
    "# Tampilkan contoh hasil\n",
    "contoh_index = 0\n",
    "print(f\"Teks Asli (setelah cleaning): \\n{X_train[contoh_index]}\")\n",
    "print(f\"\\nSetelah diubah menjadi sekuens angka: \\n{X_train_sequences[contoh_index]}\")\n",
    "print(f\"\\nSetelah di-padding menjadi {MAX_SEQUENCE_LENGTH} elemen: \\n{X_train_padded[contoh_index]}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Bentuk (shape) dari data latih akhir: {X_train_padded.shape}\")\n",
    "print(f\"Bentuk (shape) dari data uji akhir: {X_test_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9b2877a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3820b4f",
   "metadata": {},
   "source": [
    "### <b> Dataset to linguistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c109bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "EMBEDDING_DIM = 64     # Ukuran vektor untuk setiap kata\n",
    "UNITS = 64             # Jumlah unit/neuron di dalam layer LSTM/GRU/RNN\n",
    "EPOCHS = 10            # Jumlah berapa kali model melihat keseluruhan data latih\n",
    "BATCH_SIZE = 32        # Jumlah data yang diproses dalam satu waktu\n",
    "PATIENCE = 3           # Berapa epoch model akan menunggu jika tidak ada peningkatan\n",
    "\n",
    "# --- Callback untuk menghentikan training lebih awal (mencegah overfitting) ---\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fb37f63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hilla\\anaconda3\\envs\\deep-learning\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.7709 - loss: 0.4037 - val_accuracy: 0.9661 - val_loss: 0.0959\n",
      "Epoch 2/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.9786 - loss: 0.0647 - val_accuracy: 0.9648 - val_loss: 0.1062\n",
      "Epoch 3/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - accuracy: 0.9905 - loss: 0.0332 - val_accuracy: 0.9658 - val_loss: 0.1097\n",
      "Epoch 4/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - accuracy: 0.9924 - loss: 0.0259 - val_accuracy: 0.9648 - val_loss: 0.1391\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM Model\n",
    "def create_lstm_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(UNITS)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(UNITS, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(2, activation='softmax') # 2 output untuk 2 kelas (judol/bukan)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Buat dan latih model LSTM\n",
    "lstm_model = create_lstm_model()\n",
    "lstm_model.summary()\n",
    "\n",
    "history_lstm = lstm_model.fit(\n",
    "    X_train_padded, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test_padded, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27c6bf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.7957 - loss: 0.3962 - val_accuracy: 0.9614 - val_loss: 0.1070\n",
      "Epoch 2/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9810 - loss: 0.0594 - val_accuracy: 0.9695 - val_loss: 0.0898\n",
      "Epoch 3/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.9901 - loss: 0.0350 - val_accuracy: 0.9658 - val_loss: 0.1051\n",
      "Epoch 4/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 40ms/step - accuracy: 0.9931 - loss: 0.0253 - val_accuracy: 0.9648 - val_loss: 0.1244\n",
      "Epoch 5/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 43ms/step - accuracy: 0.9941 - loss: 0.0193 - val_accuracy: 0.9644 - val_loss: 0.1246\n"
     ]
    }
   ],
   "source": [
    "# Train GRU Model\n",
    "def create_gru_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(UNITS)), # Cukup ganti LSTM dengan GRU\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(UNITS, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Buat dan latih model GRU\n",
    "gru_model = create_gru_model()\n",
    "gru_model.summary()\n",
    "\n",
    "history_gru = gru_model.fit(\n",
    "    X_train_padded, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test_padded, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a09ade5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 33ms/step - accuracy: 0.7160 - loss: 0.4950 - val_accuracy: 0.9597 - val_loss: 0.1142\n",
      "Epoch 2/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.9813 - loss: 0.0623 - val_accuracy: 0.9672 - val_loss: 0.1043\n",
      "Epoch 3/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9911 - loss: 0.0271 - val_accuracy: 0.9597 - val_loss: 0.1239\n",
      "Epoch 4/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9941 - loss: 0.0198 - val_accuracy: 0.9638 - val_loss: 0.1428\n",
      "Epoch 5/10\n",
      "\u001b[1m370/370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9946 - loss: 0.0163 - val_accuracy: 0.9631 - val_loss: 0.1539\n"
     ]
    }
   ],
   "source": [
    "# Train Simple RNN (baseline)\n",
    "def create_rnn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(UNITS)), # Menggunakan SimpleRNN\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(UNITS, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Buat dan latih model RNN\n",
    "rnn_model = create_rnn_model()\n",
    "rnn_model.summary()\n",
    "\n",
    "history_rnn = rnn_model.fit(\n",
    "    X_train_padded, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test_padded, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d24869",
   "metadata": {},
   "source": [
    "### <b> Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21607713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name=\"\"):\n",
    "    print(f\"\\n--- Evaluasi Model: {model_name} ---\")\n",
    "\n",
    "    # Dapatkan prediksi dari model\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Hitung metrik\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Akurasi: {accuracy:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "    print(\"\\nLaporan Klasifikasi:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Bukan Judol (0)', 'Judol (1)']))\n",
    "\n",
    "    # 3. Kembalikan metrik untuk tabel perbandingan\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89915f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Memulai Evaluasi untuk Semua Model ---\n",
      "\n",
      "--- Evaluasi Model: LSTM ---\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "Laporan Klasifikasi:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Bukan Judol (0)       0.95      0.98      0.97      1477\n",
      "      Judol (1)       0.98      0.95      0.97      1476\n",
      "\n",
      "       accuracy                           0.97      2953\n",
      "      macro avg       0.97      0.97      0.97      2953\n",
      "   weighted avg       0.97      0.97      0.97      2953\n",
      "\n",
      "\n",
      "--- Evaluasi Model: GRU ---\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "Laporan Klasifikasi:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Bukan Judol (0)       0.97      0.97      0.97      1477\n",
      "      Judol (1)       0.97      0.97      0.97      1476\n",
      "\n",
      "       accuracy                           0.97      2953\n",
      "      macro avg       0.97      0.97      0.97      2953\n",
      "   weighted avg       0.97      0.97      0.97      2953\n",
      "\n",
      "\n",
      "--- Evaluasi Model: SimpleRNN ---\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Laporan Klasifikasi:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Bukan Judol (0)       0.95      0.98      0.97      1477\n",
      "      Judol (1)       0.98      0.95      0.97      1476\n",
      "\n",
      "       accuracy                           0.97      2953\n",
      "      macro avg       0.97      0.97      0.97      2953\n",
      "   weighted avg       0.97      0.97      0.97      2953\n",
      "\n",
      "\n",
      "\n",
      "===== RINGKASAN AKHIR PERBANDINGAN MODEL =====\n",
      "        Model  Akurasi  F1-Score (Weighted)\n",
      "1         GRU   0.9695               0.9695\n",
      "2  Simple RNN   0.9672               0.9671\n",
      "0        LSTM   0.9661               0.9661\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name=\"\"):\n",
    "    print(f\"\\n--- Evaluasi Model: {model_name} ---\")\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    print(\"Laporan Klasifikasi:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Bukan Judol (0)', 'Judol (1)']))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return accuracy, f1\n",
    "\n",
    "print(\"--- Memulai Evaluasi untuk Semua Model ---\")\n",
    "acc_lstm, f1_lstm = evaluate_model(lstm_model, X_test_padded, y_test, \"LSTM\")\n",
    "acc_gru, f1_gru = evaluate_model(gru_model, X_test_padded, y_test, \"GRU\")\n",
    "acc_rnn, f1_rnn = evaluate_model(rnn_model, X_test_padded, y_test, \"SimpleRNN\")\n",
    "\n",
    "# Comparation table\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': ['LSTM', 'GRU', 'Simple RNN'],\n",
    "    'Akurasi': [acc_lstm, acc_gru, acc_rnn],\n",
    "    'F1-Score (Weighted)': [f1_lstm, f1_gru, f1_rnn]\n",
    "})\n",
    "\n",
    "# Urutkan berdasarkan performa terbaik\n",
    "summary_df = summary_df.sort_values(by='F1-Score (Weighted)', ascending=False)\n",
    "\n",
    "print(\"\\n\\n===== RINGKASAN AKHIR PERBANDINGAN MODEL =====\")\n",
    "print(summary_df.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
